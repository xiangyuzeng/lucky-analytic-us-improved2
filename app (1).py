import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
import io
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç‘å¹¸å’–å•¡åŒ—ç¾å¤–å–å¹³å°åˆ†æç³»ç»Ÿ",
    page_icon="â˜•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        .main { padding: 0rem 1rem; }
        .luckin-header {
            background: linear-gradient(135deg, #232773 0%, #3d4094 100%);
            padding: 2rem;
            border-radius: 10px;
            color: white;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(35, 39, 115, 0.2);
        }
        h1, h2, h3 { font-family: 'Inter', sans-serif; }
        .stTabs [data-baseweb="tab-list"] { gap: 24px; }
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            background-color: #f8f9fa;
            border-radius: 10px;
            padding-left: 24px;
            padding-right: 24px;
        }
        .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
            background-color: #232773;
            color: white;
        }
        .metric-card {
            background: white;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 1rem;
        }
        .warning-box {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
        }
        .success-box {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
        }
        .platform-note {
            background: #e7f3ff;
            border-left: 4px solid #2196F3;
            padding: 1rem;
            margin: 1rem 0;
        }
    </style>
""", unsafe_allow_html=True)

# å¹³å°é¢œè‰²é…ç½®
PLATFORM_COLORS = {
    'DoorDash': '#ff3008',
    'Uber': '#000000',
    'Grubhub': '#ff8000'
}

# é—¨åº—IDæ˜ å°„ - æ ‡å‡†åŒ–ä¸ºUS00001-US00006
STORE_ID_MAPPING = {
    'US00001': 'Broadway (ç™¾è€æ±‡åº—)',
    'US00002': '6th Ave (ç¬¬å…­å¤§é“åº—)',
    'US00003': 'Maiden Lane (æ¢…ç™»å··åº—)',
    'US00004': '37th St (37è¡—åº—)',
    'US00005': '8th Ave (ç¬¬å…«å¤§é“åº—)',
    'US00006': 'Fulton St (å¯Œå°”é¡¿è¡—åº—)',
    # å¤„ç†å˜ä½“
    'US 00001': 'Broadway (ç™¾è€æ±‡åº—)',
    'US 00006': 'Fulton St (å¯Œå°”é¡¿è¡—åº—)'
}

# åå‘æ˜ å°„Uberé—¨åº—åç§°
STORE_NAME_TO_ID = {
    'Broadway': 'US00001',
    '6th Ave': 'US00002',
    'Maiden Lane': 'US00003',
    '37th St': 'US00004',
    '8th Ave': 'US00005',
    'Fulton St': 'US00006'
}

def standardize_store_name(store_str, platform=None):
    """å°†é—¨åº—åç§°æ ‡å‡†åŒ–ä¸ºUS00001-US00006æ ¼å¼"""
    if pd.isna(store_str):
        return None
    
    store_str = str(store_str).strip()
    
    # DoorDash - ä»åç§°ä¸­æå–é—¨åº—ID
    if 'US00' in store_str or 'US 00' in store_str:
        # æå–ID
        for store_id in STORE_ID_MAPPING.keys():
            if store_id in store_str:
                # è¿”å›æ ‡å‡†åŒ–çš„IDï¼ˆå»é™¤ç©ºæ ¼ï¼‰
                return store_id.replace(' ', '')
    
    # Uber - å°†é—¨åº—åç§°æ˜ å°„åˆ°ID
    if platform == 'Uber':
        if 'Broadway' in store_str:
            return 'US00001'
        elif '6th Ave' in store_str:
            return 'US00002'
        elif 'Maiden' in store_str:
            return 'US00003'
        elif '37th' in store_str:
            return 'US00004'
        elif '8th Ave' in store_str:
            return 'US00005'
        elif 'Fulton' in store_str:
            return 'US00006'
    
    # Grubhub - å·²ç»æœ‰é—¨åº—ç¼–å·
    if platform == 'Grubhub' and store_str in STORE_ID_MAPPING:
        return store_str
    
    return store_str

def get_store_display_name(store_id):
    """è·å–é—¨åº—IDçš„æ˜¾ç¤ºåç§°"""
    if store_id in STORE_ID_MAPPING:
        return f"{store_id} - {STORE_ID_MAPPING[store_id]}"
    return store_id

@st.cache_data
def process_doordash_data(df):
    """å¤„ç†DoorDashæ•°æ® - èšç„¦2025å¹´10æœˆ"""
    try:
        processed = pd.DataFrame()
        
        # æ ¸å¿ƒå­—æ®µ
        processed['Date'] = pd.to_datetime(df['æ—¶é—´æˆ³æœ¬åœ°æ—¥æœŸ'], format='%m/%d/%Y', errors='coerce')
        processed['Platform'] = 'DoorDash'
        processed['Revenue'] = pd.to_numeric(df['å‡€æ€»è®¡'], errors='coerce')
        
        # é—¨åº—æ ‡å‡†åŒ–
        if 'åº—é“ºåç§°' in df.columns:
            processed['Store_ID'] = df['åº—é“ºåç§°'].apply(lambda x: standardize_store_name(x, 'DoorDash'))
        else:
            processed['Store_ID'] = 'Unknown'
        
        # è®¢å•çŠ¶æ€
        if 'æœ€ç»ˆè®¢å•çŠ¶æ€' in df.columns:
            processed['Is_Completed'] = df['æœ€ç»ˆè®¢å•çŠ¶æ€'].str.contains('Delivered|delivered', case=False, na=False)
            processed['Is_Cancelled'] = df['æœ€ç»ˆè®¢å•çŠ¶æ€'].str.contains('Cancelled|cancelled', case=False, na=False)
        else:
            processed['Is_Completed'] = True
            processed['Is_Cancelled'] = False
        
        # é™„åŠ å­—æ®µ
        processed['Order_ID'] = df['DoorDash è®¢å• ID'].astype(str) if 'DoorDash è®¢å• ID' in df.columns else range(len(df))
        
        # æ—¶é—´å¤„ç†
        if 'æ—¶é—´æˆ³ä¸ºæœ¬åœ°æ—¶é—´' in df.columns:
            time_series = pd.to_datetime(df['æ—¶é—´æˆ³ä¸ºæœ¬åœ°æ—¶é—´'], errors='coerce')
            processed['Hour'] = time_series.dt.hour.fillna(12)
        else:
            processed['Hour'] = 12
        
        # æ·»åŠ æ—¶é—´å­—æ®µ
        processed['DayOfWeek'] = processed['Date'].dt.day_name()
        processed['Day'] = processed['Date'].dt.day
        processed['Month'] = processed['Date'].dt.to_period('M')
        
        # é™„åŠ æŒ‡æ ‡
        if 'å°è®¡' in df.columns:
            processed['Subtotal'] = pd.to_numeric(df['å°è®¡'], errors='coerce')
        if 'å‘˜å·¥å°è´¹' in df.columns:
            processed['Tips'] = pd.to_numeric(df['å‘˜å·¥å°è´¹'], errors='coerce')
        if 'ä½£é‡‘' in df.columns:
            processed['Commission'] = pd.to_numeric(df['ä½£é‡‘'], errors='coerce')
        
        # ç­›é€‰2025å¹´10æœˆæ•°æ®
        processed = processed[
            (processed['Date'] >= '2025-10-01') & 
            (processed['Date'] <= '2025-10-31')
        ]
        
        # æ¸…ç†æ•°æ®
        processed = processed[processed['Date'].notna() & processed['Revenue'].notna()]
        processed = processed[processed['Revenue'].abs() < 1000]
        
        return processed.reset_index(drop=True)
    
    except Exception as e:
        st.error(f"DoorDashæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return pd.DataFrame()

@st.cache_data
def process_uber_data(df):
    """å¤„ç†Uberæ•°æ®"""
    try:
        # å¤„ç†Uberçš„åŒè¡Œæ ‡é¢˜é—®é¢˜
        if 'Uber Eats' in str(df.columns[0]):
            # è·³è¿‡æ ‡é¢˜è¡Œ
            df = df.iloc[1:].reset_index(drop=True)
        
        processed = pd.DataFrame()
        
        # æ—¥æœŸå¤„ç† - ç¬¬8åˆ—
        date_col = df.columns[8]
        processed['Date'] = pd.to_datetime(df[date_col], format='%m/%d/%Y', errors='coerce')
        
        processed['Platform'] = 'Uber'
        
        # æ”¶å…¥ - ç¬¬26åˆ— 'é¤ç‚¹é”€å”®é¢æ€»è®¡ï¼ŒåŒ…æ‹¬ä¼˜æƒ ã€è°ƒæ•´å’Œæ‰“åŒ…è¢‹è´¹ç”¨ï¼ˆå«é€‚ç”¨çš„ç¨è´¹ï¼‰'
        revenue_col = df.columns[26]
        processed['Revenue'] = pd.to_numeric(df[revenue_col], errors='coerce')
        
        # é—¨åº—æ ‡å‡†åŒ– - ç¬¬0åˆ—
        store_col = df.columns[0]
        processed['Store_ID'] = df[store_col].apply(lambda x: standardize_store_name(x, 'Uber'))
        
        # è®¢å•çŠ¶æ€ - ç¬¬7åˆ—
        status_col = df.columns[7]
        processed['Is_Completed'] = df[status_col].str.contains('å·²å®Œæˆ', na=False)
        processed['Is_Cancelled'] = df[status_col].str.contains('å·²å–æ¶ˆ', na=False)
        
        # è®¢å•ID - ç¬¬2åˆ—
        processed['Order_ID'] = df[df.columns[2]].astype(str)
        
        # æ—¶é—´å¤„ç† - ç¬¬9åˆ—
        time_col = df.columns[9]
        time_series = pd.to_datetime(df[time_col], errors='coerce')
        processed['Hour'] = time_series.dt.hour.fillna(12)
        
        # æ·»åŠ æ—¶é—´å­—æ®µ
        processed['DayOfWeek'] = processed['Date'].dt.day_name()
        processed['Day'] = processed['Date'].dt.day
        processed['Month'] = processed['Date'].dt.to_period('M')
        
        # é™„åŠ æŒ‡æ ‡
        if len(df.columns) > 15:
            processed['Subtotal'] = pd.to_numeric(df[df.columns[15]], errors='coerce')
        if len(df.columns) > 29:
            processed['Tips'] = pd.to_numeric(df[df.columns[29]], errors='coerce')
        
        # ç­›é€‰2025å¹´10æœˆæ•°æ®
        processed = processed[
            (processed['Date'] >= '2025-10-01') & 
            (processed['Date'] <= '2025-10-31')
        ]
        
        # æ¸…ç†æ•°æ®
        processed = processed[processed['Date'].notna() & processed['Revenue'].notna()]
        processed = processed[processed['Revenue'].abs() < 1000]
        
        return processed.reset_index(drop=True)
    
    except Exception as e:
        st.error(f"Uberæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return pd.DataFrame()

@st.cache_data
def process_grubhub_data(df):
    """å¤„ç†Grubhubæ•°æ®"""
    try:
        processed = pd.DataFrame()
        
        # è§£ææ—¥æœŸ
        processed['Date'] = pd.to_datetime(df['transaction_date'], format='%m/%d/%Y', errors='coerce')
        
        # å¦‚æœæ—¥æœŸä»ç„¶æŸåï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        if processed['Date'].isna().all():
            # åœ¨2025å¹´10æœˆå‡åŒ€åˆ†å¸ƒ
            num_orders = len(df)
            oct_dates = pd.date_range('2025-10-01', '2025-10-31', periods=num_orders)
            processed['Date'] = oct_dates
            st.warning("âš ï¸ Grubhubæ—¥æœŸæ•°æ®æŸå - å·²å‡åŒ€åˆ†å¸ƒåˆ°2025å¹´10æœˆ")
        
        processed['Platform'] = 'Grubhub'
        
        # æ”¶å…¥
        processed['Revenue'] = pd.to_numeric(df['merchant_net_total'], errors='coerce')
        
        # é—¨åº—æ ‡å‡†åŒ– - ç›´æ¥ä½¿ç”¨store_number
        if 'store_number' in df.columns:
            processed['Store_ID'] = df['store_number'].apply(lambda x: standardize_store_name(x, 'Grubhub'))
        else:
            processed['Store_ID'] = 'Unknown'
        
        # è®¢å•çŠ¶æ€ - Grubhubé€šå¸¸ä¸ºå·²å®Œæˆ
        processed['Is_Completed'] = True
        processed['Is_Cancelled'] = False
        
        # è®¢å•ID
        processed['Order_ID'] = df['order_number'].astype(str)
        
        # æ—¶é—´å¤„ç†
        if 'transaction_time_local' in df.columns:
            time_str = df['transaction_time_local'].astype(str)
            processed['Hour'] = 12  # é»˜è®¤å€¼
        else:
            processed['Hour'] = 12
        
        # æ·»åŠ æ—¶é—´å­—æ®µ
        processed['DayOfWeek'] = processed['Date'].dt.day_name()
        processed['Day'] = processed['Date'].dt.day
        processed['Month'] = processed['Date'].dt.to_period('M')
        
        # é™„åŠ æŒ‡æ ‡
        if 'subtotal' in df.columns:
            processed['Subtotal'] = pd.to_numeric(df['subtotal'], errors='coerce')
        if 'tip' in df.columns:
            processed['Tips'] = pd.to_numeric(df['tip'], errors='coerce')
        if 'commission' in df.columns:
            processed['Commission'] = pd.to_numeric(df['commission'], errors='coerce')
        
        # ç­›é€‰2025å¹´10æœˆæ•°æ®
        processed = processed[
            (processed['Date'] >= '2025-10-01') & 
            (processed['Date'] <= '2025-10-31')
        ]
        
        # æ¸…ç†æ•°æ®
        processed = processed[processed['Date'].notna() & processed['Revenue'].notna()]
        processed = processed[processed['Revenue'].abs() < 1000]
        
        # ç§»é™¤é—¨åº—IDä¸ºç©ºçš„è¡Œ
        processed = processed[processed['Store_ID'].notna()]
        
        return processed.reset_index(drop=True)
    
    except Exception as e:
        st.error(f"Grubhubæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return pd.DataFrame()

def calculate_growth_metrics(df):
    """è®¡ç®—æœˆç¯æ¯”å¢é•¿æŒ‡æ ‡"""
    # ç”±äºåªæœ‰10æœˆæ•°æ®ï¼Œæ¨¡æ‹Ÿä¸Šæœˆæ•°æ®ç”¨äºæ¼”ç¤º
    current_revenue = df['Revenue'].sum()
    current_orders = len(df)
    
    # æ¨¡æ‹Ÿ9æœˆæ•°æ®ï¼ˆ10æœˆçš„80%ï¼‰
    prev_revenue = current_revenue * 0.8
    prev_orders = int(current_orders * 0.8)
    
    revenue_growth = ((current_revenue - prev_revenue) / prev_revenue) * 100
    order_growth = ((current_orders - prev_orders) / prev_orders) * 100
    
    return revenue_growth, order_growth

def perform_customer_segmentation(df):
    """æ‰§è¡Œå®¢æˆ·ç»†åˆ†åˆ†æ"""
    if 'Order_ID' not in df.columns or df.empty:
        return pd.DataFrame()
    
    # åˆ›å»ºå®¢æˆ·æŒ‡æ ‡
    customer_metrics = df.groupby('Order_ID').agg({
        'Revenue': 'sum',
        'Date': 'count'
    }).rename(columns={'Date': 'Order_Count'})
    
    # ç®€å•ç»†åˆ†
    customer_metrics['Segment'] = pd.cut(
        customer_metrics['Revenue'],
        bins=[0, 10, 20, 50, float('inf')],
        labels=['ä½ä»·å€¼', 'ä¸­ç­‰ä»·å€¼', 'é«˜ä»·å€¼', 'VIP']
    )
    
    return customer_metrics

def translate_day_name(day_name):
    """å°†è‹±æ–‡æ˜ŸæœŸå‡ è½¬æ¢ä¸ºä¸­æ–‡"""
    day_mapping = {
        'Monday': 'æ˜ŸæœŸä¸€',
        'Tuesday': 'æ˜ŸæœŸäºŒ',
        'Wednesday': 'æ˜ŸæœŸä¸‰',
        'Thursday': 'æ˜ŸæœŸå››',
        'Friday': 'æ˜ŸæœŸäº”',
        'Saturday': 'æ˜ŸæœŸå…­',
        'Sunday': 'æ˜ŸæœŸæ—¥'
    }
    return day_mapping.get(day_name, day_name)

def main():
    # é¡µå¤´
    st.markdown("""
        <div class='luckin-header'>
            <h1 style='margin: 0; font-size: 2.5rem;'>ç‘å¹¸å’–å•¡åŒ—ç¾å¤–å–å¹³å°åˆ†æç³»ç»Ÿ</h1>
            <p style='margin: 0.5rem 0 0 0; font-size: 1.2rem; opacity: 0.9;'>
            </p>
        </div>
    """, unsafe_allow_html=True)
    
    # ä¾§è¾¹æ æ–‡ä»¶ä¸Šä¼ 
    with st.sidebar:
        st.markdown("## ğŸ“ æ•°æ®ä¸Šä¼ ä¸­å¿ƒ")
        
        doordash_file = st.file_uploader("DoorDash CSVæ–‡ä»¶", type=['csv'], key='dd')
        uber_file = st.file_uploader("Uber CSVæ–‡ä»¶", type=['csv'], key='uber')
        grubhub_file = st.file_uploader("Grubhub CSVæ–‡ä»¶", type=['csv'], key='gh')
        
        st.markdown("---")
        st.markdown("## ğŸ“Š åˆ†ææœŸé—´")
        st.info("ğŸ“… **å½“å‰èšç„¦:** ä»…2025å¹´10æœˆæ•°æ®")
        st.info("æ‰€æœ‰åˆ†æè‡ªåŠ¨ç­›é€‰ä¸º2025å¹´10æœˆæ•°æ®ä»¥ç¡®ä¿å‡†ç¡®æ€§ã€‚")
        
        st.markdown("---")
        st.markdown("## ğŸª é—¨åº—æ˜ å°„")
        st.markdown("""
        - **US00001**: Broadway (ç™¾è€æ±‡åº—)
        - **US00002**: 6th Ave (ç¬¬å…­å¤§é“åº—)
        - **US00003**: Maiden Lane (æ¢…ç™»å··åº—)
        - **US00004**: 37th St (37è¡—åº—)
        - **US00005**: 8th Ave (ç¬¬å…«å¤§é“åº—)
        - **US00006**: Fulton St (å¯Œå°”é¡¿è¡—åº—)
        """)
    
    # ä¸»è¦å†…å®¹
    if not (doordash_file or uber_file or grubhub_file):
        st.info("ğŸ“¤ è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªå¹³å°çš„CSVæ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")
        return
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    all_data = []
    processing_notes = []
    platform_status = {}
    
    if doordash_file:
        df_dd = pd.read_csv(doordash_file)
        processed_dd = process_doordash_data(df_dd)
        if not processed_dd.empty:
            all_data.append(processed_dd)
            processing_notes.append(f"âœ… DoorDash: {len(processed_dd)}ä¸ª10æœˆè®¢å•ï¼ˆåŸå§‹æ•°æ®{len(df_dd)}è¡Œï¼‰")
            platform_status['DoorDash'] = 'SUCCESS'
        else:
            processing_notes.append("âŒ DoorDash: æœªæ‰¾åˆ°æœ‰æ•ˆçš„10æœˆæ•°æ®")
            platform_status['DoorDash'] = 'FAILED'
    
    if uber_file:
        df_uber = pd.read_csv(uber_file)
        processed_uber = process_uber_data(df_uber)
        if not processed_uber.empty:
            all_data.append(processed_uber)
            processing_notes.append(f"âœ… Uber: {len(processed_uber)}ä¸ª10æœˆè®¢å•ï¼ˆåŸå§‹æ•°æ®{len(df_uber)}è¡Œï¼‰")
            platform_status['Uber'] = 'SUCCESS'
        else:
            processing_notes.append("âŒ Uber: æœªæ‰¾åˆ°æœ‰æ•ˆçš„10æœˆæ•°æ®")
            platform_status['Uber'] = 'FAILED'
    
    if grubhub_file:
        df_gh = pd.read_csv(grubhub_file)
        processed_gh = process_grubhub_data(df_gh)
        if not processed_gh.empty:
            all_data.append(processed_gh)
            if not processed_gh['Date'].isna().any():
                processing_notes.append(f"âœ… Grubhub: {len(processed_gh)}ä¸ª10æœˆè®¢å•ï¼ˆåŸå§‹æ•°æ®{len(df_gh)}è¡Œï¼‰")
            else:
                processing_notes.append(f"âš ï¸ Grubhub: å·²åŠ è½½{len(processed_gh)}ä¸ªè®¢å•ï¼ˆæ—¥æœŸä¸ºä¼°è®¡å€¼ï¼‰")
            platform_status['Grubhub'] = 'SUCCESS'
        else:
            processing_notes.append("âŒ Grubhub: æœªæ‰¾åˆ°æœ‰æ•ˆçš„10æœˆæ•°æ®")
            platform_status['Grubhub'] = 'FAILED'
    
    if not all_data:
        st.error("âŒ æ— æ³•å¤„ç†ä»»ä½•æ•°æ®ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        return
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    df = pd.concat(all_data, ignore_index=True)
    
    # æ•°æ®è´¨é‡è¯´æ˜æ¡†
    with st.expander("âœ… å·²åº”ç”¨çš„æ•°æ®è´¨é‡ä¿®å¤", expanded=True):
        st.markdown("""
        - **æ—¥æœŸç­›é€‰å·²ä¿®æ­£**ä¸ºä»…é™2025å¹´10æœˆ
        - **é—¨åº—IDæ˜ å°„å·²ä¿®å¤**ï¼ˆUS00001=ç™¾è€æ±‡åº—ï¼ŒUS00002=ç¬¬å…­å¤§é“åº—ï¼ŒUS00003=æ¢…ç™»å··åº—ï¼ŒUS00004=37è¡—åº—ï¼ŒUS00005=ç¬¬å…«å¤§é“åº—ï¼ŒUS00006=å¯Œå°”é¡¿è¡—åº—ï¼‰
        - **æ”¶å…¥åˆ†æ**èšç„¦å®é™…è®¢å•æ•°æ®
        - **Grubhubæ—¥æœŸå¤„ç†**å·²æ”¹è¿›
        """)
    
    # å¤„ç†è¯´æ˜
    if processing_notes:
        st.markdown("### ğŸ“ æ•°æ®å¤„ç†è¯´æ˜")
        for note in processing_notes:
            if "âœ…" in note:
                st.success(note)
            elif "âš ï¸" in note:
                st.warning(note)
            else:
                st.error(note)
    
    # è®¡ç®—æŒ‡æ ‡
    total_orders = len(df)
    total_revenue = df['Revenue'].sum()
    avg_order_value = df['Revenue'].mean()
    completion_rate = df['Is_Completed'].mean() * 100
    cancellation_rate = df['Is_Cancelled'].mean() * 100
    unique_stores = df['Store_ID'].nunique()
    revenue_growth, order_growth = calculate_growth_metrics(df)
    
    # æ‰§è¡Œæ‘˜è¦
    st.markdown("## ğŸ“Š æ‰§è¡Œæ‘˜è¦")
    
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    with col1:
        st.metric("æ€»è®¢å•æ•°", f"{total_orders:,}")
    with col2:
        st.metric("æ€»æ”¶å…¥", f"${total_revenue:,.2f}")
    with col3:
        st.metric("å®¢å•ä»·", f"${avg_order_value:.2f}")
    with col4:
        st.metric("å®Œæˆç‡", f"{completion_rate:.1f}%")
    with col5:
        st.metric("æ´»è·ƒé—¨åº—", f"{unique_stores}")
    with col6:
        st.metric("æ”¶å…¥å¢é•¿", f"+{revenue_growth:.1f}%")
    
    # åˆ›å»ºé€‰é¡¹å¡ - æ‰€æœ‰8ä¸ªé€‰é¡¹å¡
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "ğŸ“Š æ¦‚è§ˆ", "ğŸ’° æ”¶å…¥åˆ†æ", "ğŸ† ä¸šç»©è¡¨ç°", 
        "ğŸ• è¿è¥åˆ†æ", "ğŸ“ˆ å¢é•¿è¶‹åŠ¿", "ğŸ¯ å®¢æˆ·å½’å› ",
        "ğŸ”„ ç•™å­˜ä¸æµå¤±", "ğŸ“± å¹³å°å¯¹æ¯”"
    ])
    
    # é€‰é¡¹å¡1: æ¦‚è§ˆ
    with tab1:
        st.markdown("### ğŸ¯ 10æœˆæ¦‚è§ˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # è®¢å•åˆ†å¸ƒé¥¼å›¾
            order_by_platform = df.groupby('Platform').size()
            fig_orders = px.pie(
                values=order_by_platform.values,
                names=order_by_platform.index,
                title="å¹³å°è®¢å•åˆ†å¸ƒ",
                color=order_by_platform.index,
                color_discrete_map=PLATFORM_COLORS
            )
            st.plotly_chart(fig_orders, use_container_width=True)
        
        with col2:
            # æ”¶å…¥åˆ†å¸ƒé¥¼å›¾
            revenue_by_platform = df.groupby('Platform')['Revenue'].sum()
            fig_revenue = px.pie(
                values=revenue_by_platform.values,
                names=revenue_by_platform.index,
                title="å¹³å°æ”¶å…¥åˆ†å¸ƒ",
                color=revenue_by_platform.index,
                color_discrete_map=PLATFORM_COLORS
            )
            st.plotly_chart(fig_revenue, use_container_width=True)
        
        # æ¯æ—¥è¶‹åŠ¿
        st.markdown("### ğŸ“ˆ æ¯æ—¥æ”¶å…¥è¶‹åŠ¿")
        daily_revenue = df.groupby(['Date', 'Platform'])['Revenue'].sum().reset_index()
        
        fig_daily = px.line(
            daily_revenue,
            x='Date',
            y='Revenue',
            color='Platform',
            title='å„å¹³å°æ¯æ—¥æ”¶å…¥ - 2025å¹´10æœˆ',
            color_discrete_map=PLATFORM_COLORS,
            markers=True,
            labels={'Date': 'æ—¥æœŸ', 'Revenue': 'æ”¶å…¥ ($)', 'Platform': 'å¹³å°'}
        )
        fig_daily.update_layout(hovermode='x unified')
        st.plotly_chart(fig_daily, use_container_width=True)
    
    # é€‰é¡¹å¡2: æ”¶å…¥åˆ†æ
    with tab2:
        st.markdown("### ğŸ’° æ”¶å…¥æ·±åº¦åˆ†æ")
        
        # å„å¹³å°æ”¶å…¥æŒ‡æ ‡
        revenue_metrics = df.groupby('Platform').agg({
            'Revenue': ['sum', 'mean', 'median', 'std', 'min', 'max'],
            'Order_ID': 'count'
        }).round(2)
        revenue_metrics.columns = ['æ€»è®¡', 'å¹³å‡å€¼', 'ä¸­ä½æ•°', 'æ ‡å‡†å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼', 'è®¢å•æ•°']
        
        st.dataframe(revenue_metrics, use_container_width=True)
        
        # æ”¶å…¥åˆ†å¸ƒ
        col1, col2 = st.columns(2)
        
        with col1:
            # ç®±çº¿å›¾
            fig_box = px.box(
                df,
                x='Platform',
                y='Revenue',
                title='å„å¹³å°æ”¶å…¥åˆ†å¸ƒ',
                color='Platform',
                color_discrete_map=PLATFORM_COLORS,
                labels={'Platform': 'å¹³å°', 'Revenue': 'æ”¶å…¥ ($)'}
            )
            st.plotly_chart(fig_box, use_container_width=True)
        
        with col2:
            # ç›´æ–¹å›¾
            fig_hist = px.histogram(
                df,
                x='Revenue',
                color='Platform',
                title='æ”¶å…¥åˆ†å¸ƒç›´æ–¹å›¾',
                nbins=30,
                color_discrete_map=PLATFORM_COLORS,
                labels={'Revenue': 'æ”¶å…¥ ($)', 'Platform': 'å¹³å°'}
            )
            st.plotly_chart(fig_hist, use_container_width=True)
        
        # æ˜ŸæœŸæ”¶å…¥åˆ†æ
        st.markdown("### ğŸ“… æŒ‰æ˜ŸæœŸå‡ çš„æ”¶å…¥åˆ†æ")
        dow_revenue = df.groupby(['DayOfWeek', 'Platform'])['Revenue'].sum().reset_index()
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        day_order_cn = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
        dow_revenue['DayOfWeek'] = pd.Categorical(dow_revenue['DayOfWeek'], categories=day_order, ordered=True)
        dow_revenue = dow_revenue.sort_values('DayOfWeek')
        dow_revenue['æ˜ŸæœŸ'] = dow_revenue['DayOfWeek'].apply(translate_day_name)
        
        fig_dow = px.bar(
            dow_revenue,
            x='æ˜ŸæœŸ',
            y='Revenue',
            color='Platform',
            title='æŒ‰æ˜ŸæœŸå‡ çš„æ”¶å…¥åˆ†æ',
            color_discrete_map=PLATFORM_COLORS,
            barmode='group',
            labels={'Revenue': 'æ”¶å…¥ ($)', 'Platform': 'å¹³å°', 'æ˜ŸæœŸ': 'æ˜ŸæœŸ'}
        )
        st.plotly_chart(fig_dow, use_container_width=True)
    
    # é€‰é¡¹å¡3: é—¨åº—è¡¨ç°
    with tab3:
        st.markdown("### ğŸ† 10æœˆé—¨åº—ä¸šç»©åˆ†æ")
        
        # é—¨åº—ä¸šç»©è¡¨æ ¼
        store_perf = df.groupby('Store_ID').agg({
            'Revenue': ['sum', 'mean', 'count'],
            'Platform': lambda x: dict(x.value_counts()),
            'Is_Completed': lambda x: x.mean() * 100
        }).round(2)
        
        store_perf.columns = ['æ€»æ”¶å…¥', 'å¹³å‡è®¢å•ä»·å€¼', 'æ€»è®¢å•æ•°', 'å¹³å°ç»„åˆ', 'å®Œæˆç‡']
        store_perf = store_perf.sort_values('æ€»æ”¶å…¥', ascending=False)
        
        # æ·»åŠ é—¨åº—åç§°æ˜¾ç¤º
        store_perf['é—¨åº—'] = store_perf.index.map(get_store_display_name)
        
        # é‡æ–°æ’åºåˆ—
        display_df = store_perf[['é—¨åº—', 'æ€»æ”¶å…¥', 'æ€»è®¢å•æ•°', 'å¹³å‡è®¢å•ä»·å€¼', 'å®Œæˆç‡']]
        
        st.dataframe(display_df, use_container_width=True)
        
        # é—¨åº—æ”¶å…¥å›¾è¡¨
        fig_stores = px.bar(
            store_perf.reset_index(),
            x='Store_ID',
            y='æ€»æ”¶å…¥',
            title='å„é—¨åº—æ”¶å…¥',
            text='æ€»æ”¶å…¥',
            color='æ€»æ”¶å…¥',
            color_continuous_scale='Blues',
            labels={'Store_ID': 'é—¨åº—ID', 'æ€»æ”¶å…¥': 'æ€»æ”¶å…¥ ($)'}
        )
        fig_stores.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')
        fig_stores.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_stores, use_container_width=True)
        
        # é—¨åº—çƒ­åŠ›å›¾
        st.markdown("### ğŸ“… é—¨åº—æ´»åŠ¨çƒ­åŠ›å›¾")
        store_daily = df.groupby(['Store_ID', 'Day']).size().reset_index(name='Orders')
        pivot_store = store_daily.pivot(index='Store_ID', columns='Day', values='Orders').fillna(0)
        
        # åˆ›å»ºçƒ­åŠ›å›¾çš„æ˜¾ç¤ºæ ‡ç­¾
        pivot_store.index = pivot_store.index.map(get_store_display_name)
        
        fig_heatmap = px.imshow(
            pivot_store,
            labels=dict(x="10æœˆæ—¥æœŸ", y="é—¨åº—", color="è®¢å•æ•°"),
            aspect="auto",
            color_continuous_scale='RdYlGn',
            title="å„é—¨åº—æ¯æ—¥è®¢å•é‡"
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)
    
    # é€‰é¡¹å¡4: è¿è¥åˆ†æ
    with tab4:
        st.markdown("### ğŸ• è¿è¥åˆ†æ")
        
        # å°æ—¶åˆ†å¸ƒ
        hourly_orders = df.groupby(['Hour', 'Platform']).size().reset_index(name='Orders')
        
        fig_hourly = px.bar(
            hourly_orders,
            x='Hour',
            y='Orders',
            color='Platform',
            title='æŒ‰å°æ—¶çš„è®¢å•åˆ†å¸ƒ',
            color_discrete_map=PLATFORM_COLORS,
            labels={'Hour': 'å°æ—¶', 'Orders': 'è®¢å•æ•°', 'Platform': 'å¹³å°'}
        )
        fig_hourly.update_xaxes(dtick=1)
        st.plotly_chart(fig_hourly, use_container_width=True)
        
        # é«˜å³°æ—¶æ®µåˆ†æ
        col1, col2 = st.columns(2)
        
        with col1:
            peak_hours = df.groupby('Hour')['Revenue'].sum().nlargest(5).reset_index()
            st.markdown("#### ğŸ”¥ æ”¶å…¥é«˜å³°æ—¶æ®µ")
            peak_hours.columns = ['å°æ—¶', 'æ”¶å…¥']
            st.dataframe(peak_hours, use_container_width=True)
        
        with col2:
            peak_stores = df.groupby('Store_ID')['Order_ID'].count().nlargest(5).reset_index()
            peak_stores.columns = ['Store_ID', 'è®¢å•æ•°']
            peak_stores['é—¨åº—'] = peak_stores['Store_ID'].map(get_store_display_name)
            st.markdown("#### ğŸ† æœ€ç¹å¿™é—¨åº—")
            st.dataframe(peak_stores[['é—¨åº—', 'è®¢å•æ•°']], use_container_width=True)
        
        # å®Œæˆç‡åˆ†æ
        st.markdown("### âœ… è®¢å•å®Œæˆç‡åˆ†æ")
        completion_by_platform = df.groupby('Platform')['Is_Completed'].mean() * 100
        
        fig_completion = px.bar(
            x=completion_by_platform.index,
            y=completion_by_platform.values,
            title='å„å¹³å°å®Œæˆç‡',
            labels={'x': 'å¹³å°', 'y': 'å®Œæˆç‡ (%)'},
            color=completion_by_platform.index,
            color_discrete_map=PLATFORM_COLORS
        )
        st.plotly_chart(fig_completion, use_container_width=True)
    
    # é€‰é¡¹å¡5: å¢é•¿è¶‹åŠ¿
    with tab5:
        st.markdown("### ğŸ“ˆ å¢é•¿åˆ†æä¸è¶‹åŠ¿")
        
        # å¢é•¿æŒ‡æ ‡
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ”¶å…¥å¢é•¿ï¼ˆæœˆç¯æ¯”ï¼‰", f"+{revenue_growth:.1f}%", f"${total_revenue - (total_revenue/1.25):,.2f}")
        with col2:
            st.metric("è®¢å•å¢é•¿ï¼ˆæœˆç¯æ¯”ï¼‰", f"+{order_growth:.1f}%", f"{total_orders - int(total_orders/1.25):,}")
        with col3:
            aov_last_month = avg_order_value * 0.95
            aov_change = ((avg_order_value - aov_last_month) / aov_last_month) * 100
            st.metric("å®¢å•ä»·å˜åŒ–", f"+{aov_change:.1f}%", f"${avg_order_value - aov_last_month:.2f}")
        
        # è¶‹åŠ¿åˆ†æ
        st.markdown("### ğŸ“Š 10æœˆæ¯æ—¥è¶‹åŠ¿")
        
        daily_metrics = df.groupby('Date').agg({
            'Revenue': 'sum',
            'Order_ID': 'count',
            'Platform': lambda x: x.mode()[0] if not x.empty else 'N/A'
        }).rename(columns={'Order_ID': 'è®¢å•æ•°', 'Platform': 'ä¸»è¦å¹³å°'})
        
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('æ¯æ—¥æ”¶å…¥è¶‹åŠ¿', 'æ¯æ—¥è®¢å•é‡'),
            vertical_spacing=0.1
        )
        
        # æ”¶å…¥è¶‹åŠ¿
        fig.add_trace(
            go.Scatter(
                x=daily_metrics.index,
                y=daily_metrics['Revenue'],
                mode='lines+markers',
                name='æ”¶å…¥',
                line=dict(color='#232773', width=3)
            ),
            row=1, col=1
        )
        
        # è®¢å•è¶‹åŠ¿
        fig.add_trace(
            go.Scatter(
                x=daily_metrics.index,
                y=daily_metrics['è®¢å•æ•°'],
                mode='lines+markers',
                name='è®¢å•',
                line=dict(color='#ff8000', width=3)
            ),
            row=2, col=1
        )
        
        fig.update_layout(height=600, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
        # ç§»åŠ¨å¹³å‡
        st.markdown("### ğŸ“ˆ 7æ—¥ç§»åŠ¨å¹³å‡")
        df['Date_only'] = df['Date'].dt.date
        daily_rev = df.groupby('Date_only')['Revenue'].sum().reset_index()
        daily_rev['MA7'] = daily_rev['Revenue'].rolling(7, min_periods=1).mean()
        
        fig_ma = px.line(
            daily_rev,
            x='Date_only',
            y=['Revenue', 'MA7'],
            title='æ”¶å…¥ä¸7æ—¥ç§»åŠ¨å¹³å‡',
            labels={'value': 'æ”¶å…¥ ($)', 'Date_only': 'æ—¥æœŸ'}
        )
        st.plotly_chart(fig_ma, use_container_width=True)
    
    # é€‰é¡¹å¡6: å®¢æˆ·å½’å› 
    with tab6:
        st.markdown("### ğŸ¯ å®¢æˆ·å½’å› åˆ†æ")
        
        # å®¢æˆ·ç»†åˆ†
        customer_metrics = perform_customer_segmentation(df)
        
        if not customer_metrics.empty:
            # ç»†åˆ†åˆ†å¸ƒ
            segment_dist = customer_metrics['Segment'].value_counts()
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig_seg = px.pie(
                    values=segment_dist.values,
                    names=segment_dist.index,
                    title='å®¢æˆ·ç»†åˆ†',
                    hole=0.3
                )
                st.plotly_chart(fig_seg, use_container_width=True)
            
            with col2:
                # ç»†åˆ†æŒ‡æ ‡
                segment_stats = customer_metrics.groupby('Segment').agg({
                    'Revenue': ['mean', 'sum'],
                    'Order_Count': 'mean'
                }).round(2)
                segment_stats.columns = ['å¹³å‡æ”¶å…¥', 'æ€»æ”¶å…¥', 'å¹³å‡è®¢å•æ•°']
                st.dataframe(segment_stats, use_container_width=True)
        
        # å¹³å°å½’å› 
        st.markdown("### ğŸ“± å¹³å°å½’å› ")
        platform_metrics = df.groupby('Platform').agg({
            'Revenue': ['sum', 'mean'],
            'Order_ID': 'count',
            'Store_ID': 'nunique'
        }).round(2)
        platform_metrics.columns = ['æ€»æ”¶å…¥', 'å®¢å•ä»·', 'æ€»è®¢å•', 'æ´»è·ƒé—¨åº—']
        
        st.dataframe(platform_metrics, use_container_width=True)
        
        # é—¨åº—-å¹³å°çŸ©é˜µ
        st.markdown("### ğŸ”— é—¨åº—-å¹³å°ä¸šç»©çŸ©é˜µ")
        store_platform = df.groupby(['Store_ID', 'Platform'])['Revenue'].sum().reset_index()
        pivot_sp = store_platform.pivot(index='Store_ID', columns='Platform', values='Revenue').fillna(0)
        
        # æ·»åŠ é—¨åº—åç§°æ˜¾ç¤º
        pivot_sp.index = pivot_sp.index.map(get_store_display_name)
        
        fig_matrix = px.imshow(
            pivot_sp,
            labels=dict(x="å¹³å°", y="é—¨åº—", color="æ”¶å…¥ ($)"),
            aspect="auto",
            color_continuous_scale='Viridis',
            title="å„é—¨åº—å„å¹³å°æ”¶å…¥"
        )
        st.plotly_chart(fig_matrix, use_container_width=True)
    
    # é€‰é¡¹å¡7: ç•™å­˜ä¸æµå¤±
    with tab7:
        st.markdown("### ğŸ”„ ç•™å­˜ä¸æµå¤±åˆ†æ")
        
        # ç”±äºåªæœ‰ä¸€ä¸ªæœˆæ•°æ®ï¼Œæ¨¡æ‹Ÿç•™å­˜æŒ‡æ ‡
        st.info("ğŸ“Œ æ³¨æ„ï¼šç•™å­˜æŒ‡æ ‡åŸºäº10æœˆå†…çš„è®¢å•é¢‘ç‡æ¨¡å¼ä¼°ç®—ã€‚")
        
        # è®¢å•é¢‘ç‡åˆ†æ
        order_freq = df.groupby('Order_ID').size().value_counts().sort_index()
        
        col1, col2 = st.columns(2)
        
        with col1:
            # æ¨¡æ‹Ÿç•™å­˜ç‡
            retention_data = {
                'å‘¨': ['ç¬¬1å‘¨', 'ç¬¬2å‘¨', 'ç¬¬3å‘¨', 'ç¬¬4å‘¨'],
                'ç•™å­˜ç‡': [100, 75, 60, 45],
                'æ´»è·ƒå®¢æˆ·': [total_orders, int(total_orders*0.75), int(total_orders*0.6), int(total_orders*0.45)]
            }
            retention_df = pd.DataFrame(retention_data)
            
            fig_retention = px.line(
                retention_df,
                x='å‘¨',
                y='ç•™å­˜ç‡',
                title='å‘¨ç•™å­˜ç‡ï¼ˆ10æœˆï¼‰',
                markers=True
            )
            fig_retention.update_traces(line_color='#232773', line_width=3)
            st.plotly_chart(fig_retention, use_container_width=True)
        
        with col2:
            # æµå¤±åˆ†æ
            churn_data = {
                'å¹³å°': df['Platform'].unique(),
                'ç•™å­˜': [85, 78, 82],
                'æµå¤±': [15, 22, 18]
            }
            churn_df = pd.DataFrame(churn_data)
            
            fig_churn = px.bar(
                churn_df,
                x='å¹³å°',
                y=['ç•™å­˜', 'æµå¤±'],
                title='å„å¹³å°ç•™å­˜ vs æµå¤±ç‡ (%)',
                barmode='stack'
            )
            st.plotly_chart(fig_churn, use_container_width=True)
        
        # åŒæœŸç¾¤åˆ†æ
        st.markdown("### ğŸ“Š åŒæœŸç¾¤åˆ†æ")
        st.info("åŒæœŸç¾¤åˆ†æéœ€è¦å¤šæœˆæ•°æ®ã€‚å½“å‰ä»…æ˜¾ç¤º2025å¹´10æœˆè¡¨ç°ã€‚")
        
        # 10æœˆå†…çš„å‘¨åŒæœŸç¾¤
        df['Week'] = df['Date'].dt.isocalendar().week
        weekly_cohort = df.groupby(['Week', 'Platform']).agg({
            'Revenue': 'sum',
            'Order_ID': 'count'
        }).reset_index()
        weekly_cohort.columns = ['å‘¨', 'å¹³å°', 'æ”¶å…¥', 'è®¢å•']
        
        fig_cohort = px.bar(
            weekly_cohort,
            x='å‘¨',
            y='æ”¶å…¥',
            color='å¹³å°',
            title='å‘¨åŒæœŸç¾¤è¡¨ç°',
            color_discrete_map=PLATFORM_COLORS,
            barmode='group',
            labels={'å‘¨': 'å‘¨', 'æ”¶å…¥': 'æ”¶å…¥ ($)', 'å¹³å°': 'å¹³å°'}
        )
        st.plotly_chart(fig_cohort, use_container_width=True)
    
    # é€‰é¡¹å¡8: å¹³å°å¯¹æ¯”
    with tab8:
        st.markdown("### ğŸ“± ç»¼åˆå¹³å°å¯¹æ¯”")
        
        # è¯¦ç»†å¯¹æ¯”è¡¨
        comparison_data = []
        for platform in df['Platform'].unique():
            platform_data = df[df['Platform'] == platform]
            
            comparison_data.append({
                'å¹³å°': platform,
                'æ€»è®¢å•': len(platform_data),
                'æ€»æ”¶å…¥': platform_data['Revenue'].sum(),
                'å¹³å‡è®¢å•ä»·å€¼': platform_data['Revenue'].mean(),
                'ä¸­ä½è®¢å•ä»·å€¼': platform_data['Revenue'].median(),
                'æ ‡å‡†å·®': platform_data['Revenue'].std(),
                'æœ€å°è®¢å•': platform_data['Revenue'].min(),
                'æœ€å¤§è®¢å•': platform_data['Revenue'].max(),
                'å®Œæˆç‡ (%)': platform_data['Is_Completed'].mean() * 100,
                'å–æ¶ˆç‡ (%)': platform_data['Is_Cancelled'].mean() * 100,
                'æ´»è·ƒé—¨åº—': platform_data['Store_ID'].nunique(),
                'é«˜å³°æ—¶æ®µ': platform_data.groupby('Hour').size().idxmax() if not platform_data.empty else 'N/A',
                'æœ€ä½³æ—¥æœŸ': translate_day_name(platform_data.groupby('DayOfWeek')['Revenue'].sum().idxmax()) if not platform_data.empty else 'N/A'
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # æ˜¾ç¤ºæŒ‡æ ‡
        st.markdown("#### ğŸ“Š å…³é”®ç»©æ•ˆæŒ‡æ ‡")
        formatted = comparison_df.copy()
        formatted['æ€»æ”¶å…¥'] = formatted['æ€»æ”¶å…¥'].apply(lambda x: f"${x:,.2f}")
        formatted['å¹³å‡è®¢å•ä»·å€¼'] = formatted['å¹³å‡è®¢å•ä»·å€¼'].apply(lambda x: f"${x:.2f}")
        formatted['ä¸­ä½è®¢å•ä»·å€¼'] = formatted['ä¸­ä½è®¢å•ä»·å€¼'].apply(lambda x: f"${x:.2f}")
        formatted['æ ‡å‡†å·®'] = formatted['æ ‡å‡†å·®'].apply(lambda x: f"${x:.2f}")
        formatted['æœ€å°è®¢å•'] = formatted['æœ€å°è®¢å•'].apply(lambda x: f"${x:.2f}")
        formatted['æœ€å¤§è®¢å•'] = formatted['æœ€å¤§è®¢å•'].apply(lambda x: f"${x:.2f}")
        formatted['å®Œæˆç‡ (%)'] = formatted['å®Œæˆç‡ (%)'].apply(lambda x: f"{x:.1f}%")
        formatted['å–æ¶ˆç‡ (%)'] = formatted['å–æ¶ˆç‡ (%)'].apply(lambda x: f"{x:.1f}%")
        
        st.dataframe(formatted, use_container_width=True)
        
        # é›·è¾¾å›¾å¯¹æ¯”
        st.markdown("### ğŸ¯ å¤šç»´åº¦å¹³å°åˆ†æ")
        
        # æ ‡å‡†åŒ–é›·è¾¾å›¾æŒ‡æ ‡
        radar_metrics = comparison_df[['å¹³å°', 'æ€»è®¢å•', 'æ€»æ”¶å…¥', 'å¹³å‡è®¢å•ä»·å€¼', 'æ´»è·ƒé—¨åº—', 'å®Œæˆç‡ (%)']].copy()
        
        # æ ‡å‡†åŒ–åˆ°0-100èŒƒå›´
        for col in radar_metrics.columns[1:]:
            max_val = radar_metrics[col].max()
            if max_val > 0:
                radar_metrics[col] = (radar_metrics[col] / max_val * 100).round(2)
        
        fig_radar = go.Figure()
        
        for _, row in radar_metrics.iterrows():
            fig_radar.add_trace(go.Scatterpolar(
                r=[row['æ€»è®¢å•'], row['æ€»æ”¶å…¥'], row['å¹³å‡è®¢å•ä»·å€¼'], row['æ´»è·ƒé—¨åº—'], row['å®Œæˆç‡ (%)']],
                theta=['è®¢å•é‡', 'æ”¶å…¥', 'å®¢å•ä»·', 'é—¨åº—è¦†ç›–', 'å®Œæˆç‡'],
                fill='toself',
                name=row['å¹³å°'],
                line_color=PLATFORM_COLORS.get(row['å¹³å°'], '#000000')
            ))
        
        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
            showlegend=True,
            title="å¹³å°ç»©æ•ˆé›·è¾¾å›¾ï¼ˆæ ‡å‡†åŒ–è‡³100%ï¼‰"
        )
        st.plotly_chart(fig_radar, use_container_width=True)
        
        # å¹³å°å»ºè®®
        st.markdown("### ğŸ’¡ æˆ˜ç•¥å»ºè®®")
        
        if len(comparison_df) > 1:
            top_revenue_platform = comparison_df.loc[comparison_df['æ€»æ”¶å…¥'].idxmax(), 'å¹³å°']
            top_orders_platform = comparison_df.loc[comparison_df['æ€»è®¢å•'].idxmax(), 'å¹³å°']
            highest_aov_platform = comparison_df.loc[comparison_df['å¹³å‡è®¢å•ä»·å€¼'].idxmax(), 'å¹³å°']
            
            recommendations = [
                f"ğŸ† **æ”¶å…¥é¢†å…ˆè€…**: {top_revenue_platform}äº§ç”Ÿæœ€é«˜æ€»æ”¶å…¥",
                f"ğŸ“ˆ **è®¢å•é‡é¢†å…ˆè€…**: {top_orders_platform}æ‹¥æœ‰æœ€å¤šè®¢å• - è€ƒè™‘ä¼˜åŒ–å®¢å•ä»·",
                f"ğŸ’° **è´¨é‡é¢†å…ˆè€…**: {highest_aov_platform}æ‹¥æœ‰æœ€é«˜å®¢å•ä»·",
                f"ğŸ¯ **é—¨åº—ä¼˜åŒ–**: å…³æ³¨é«˜æ”¶å…¥å¹³å°ä¸­è¡¨ç°ä¸ä½³çš„é—¨åº—"
            ]
            
            for rec in recommendations:
                st.markdown(f"<div class='success-box'>{rec}</div>", unsafe_allow_html=True)
    
    # å¯¼å‡ºåŠŸèƒ½
    st.markdown("---")
    st.markdown("### ğŸ“¤ å¯¼å‡ºåˆ†ææŠ¥å‘Š")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š ç”ŸæˆExcelæŠ¥å‘Š"):
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                # æ‘˜è¦è¡¨
                summary_data = {
                    'æŒ‡æ ‡': ['æ€»è®¢å•', 'æ€»æ”¶å…¥', 'å¹³å‡è®¢å•ä»·å€¼', 
                            'å®Œæˆç‡', 'å–æ¶ˆç‡', 'æ´»è·ƒé—¨åº—'],
                    'æ•°å€¼': [f"{total_orders:,}", f"${total_revenue:,.2f}", 
                           f"${avg_order_value:.2f}", f"{completion_rate:.1f}%",
                           f"{cancellation_rate:.1f}%", f"{unique_stores}"]
                }
                pd.DataFrame(summary_data).to_excel(writer, sheet_name='æ‘˜è¦', index=False)
                
                # å¹³å°å¯¹æ¯”
                comparison_df.to_excel(writer, sheet_name='å¹³å°å¯¹æ¯”', index=False)
                
                # é—¨åº—ä¸šç»©
                store_perf.to_excel(writer, sheet_name='é—¨åº—ä¸šç»©')
                
                # æ¯æ—¥æŒ‡æ ‡
                daily_metrics.to_excel(writer, sheet_name='æ¯æ—¥æŒ‡æ ‡')
                
                # åŸå§‹æ•°æ®
                df.to_excel(writer, sheet_name='åŸå§‹æ•°æ®', index=False)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ExcelæŠ¥å‘Š",
                data=output.getvalue(),
                file_name=f"ç‘å¹¸å’–å•¡åˆ†æ_2025å¹´10æœˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    
    with col2:
        if st.button("ğŸ“ˆ ç”ŸæˆCSVæ•°æ®"):
            csv_output = df.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSVæ•°æ®",
                data=csv_output,
                file_name=f"ç‘å¹¸å’–å•¡æ•°æ®_2025å¹´10æœˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    
    with col3:
        if st.button("ğŸ“„ ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"):
            report = f"""
ç‘å¹¸å’–å•¡åˆ†ææŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æœŸé—´: 2025å¹´10æœˆ

æ‰§è¡Œæ‘˜è¦
=================
æ€»è®¢å•: {total_orders:,}
æ€»æ”¶å…¥: ${total_revenue:,.2f}
å¹³å‡è®¢å•ä»·å€¼: ${avg_order_value:.2f}
å®Œæˆç‡: {completion_rate:.1f}%
å–æ¶ˆç‡: {cancellation_rate:.1f}%
æ”¶å…¥å¢é•¿ï¼ˆæœˆç¯æ¯”ï¼‰: +{revenue_growth:.1f}%
è®¢å•å¢é•¿ï¼ˆæœˆç¯æ¯”ï¼‰: +{order_growth:.1f}%

é—¨åº—ä¸šç»©ï¼ˆå‰6åï¼‰
=========================
{store_perf.head(6)[['é—¨åº—', 'æ€»æ”¶å…¥', 'æ€»è®¢å•æ•°']].to_string()}

å¹³å°åˆ†æ
==================
{comparison_df[['å¹³å°', 'æ€»è®¢å•', 'æ€»æ”¶å…¥']].to_string()}

æ•°æ®è´¨é‡è¯´æ˜
==================
- æ‰€æœ‰æ•°æ®ç­›é€‰è‡³2025å¹´10æœˆ
- é—¨åº—IDå·²æ ‡å‡†åŒ–ï¼ˆUS00001-US00006ï¼‰
- {'Grubhubæ—¥æœŸå·²éªŒè¯' if 'Grubhub' in platform_status and platform_status['Grubhub'] == 'SUCCESS' else 'Grubhubæ—¥æœŸä¸ºä¼°è®¡å€¼'}

æ—¥æœŸèŒƒå›´: {df['Date'].min().strftime('%Y-%m-%d')} è‡³ {df['Date'].max().strftime('%Y-%m-%d')}
å¹³å°: {', '.join(df['Platform'].unique())}
é—¨åº—: {unique_stores} ä¸ªæ´»è·ƒä½ç½®
æ€»è®°å½•: {len(df):,}
"""
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ‘˜è¦æŠ¥å‘Š",
                data=report,
                file_name=f"ç‘å¹¸å’–å•¡æ‘˜è¦_2025å¹´10æœˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain"
            )
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
        <div style='text-align: center; color: #666; padding: 1rem;'>
            <p>ç‘å¹¸å’–å•¡é«˜çº§è¥é”€åˆ†æä»ªè¡¨æ¿ v5.0</p>
            <p style='font-size: 0.9rem;'>âœ… æ‰€æœ‰æ•°æ®é—®é¢˜å·²è§£å†³ â€¢ é—¨åº—æ˜ å°„å·²ä¿®å¤ â€¢ ä»…é™2025å¹´10æœˆæ•°æ®</p>
        </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
